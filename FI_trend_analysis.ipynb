{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "FI_trend_analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy1OAwnJ1FuE"
      },
      "source": [
        "**Building a dataset to analyze the correlation between GTO Fixed Income trading\n",
        "with that of US Treasuries and the volatility index (MOVE Index)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxI5pyav1FuG"
      },
      "source": [
        "### **Run our regressions over a 5yr period for Daily data with the MOVE Index**\n",
        "\n",
        "In this analysis, we will not have to resample the data in the same series since all data is now daily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ8r4A1S1FuI"
      },
      "source": [
        "pip install pmdarima"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX1Ep1gz1FuN"
      },
      "source": [
        "#load libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Load specific forecasting tools\n",
        "from statsmodels.tsa.arima_model import ARMA,ARMAResults,ARIMA,ARIMAResults\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from pmdarima import auto_arima\n",
        "from statsmodels.tools.eval_measures import rmse\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose      # for ETS Plots\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf # for determining (p,q) orders\n",
        "\n",
        "# Ignore harmless warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Writing data to excel to share with Exec team\n",
        "# !pip install XlsxWriter\n",
        "# !pip install openpyxl\n",
        "# import openpyxl\n",
        "# from openpyxl import Workbook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNWFEIbr1cYL"
      },
      "source": [
        "#Load our datasets\n",
        "DATA_PATH = \"/content/drive/My Drive/Projects/FixedIncome_TA\"\n",
        "fi_data = open(DATA_PATH+'/DailyTradeCounts_2016_2020.xlsx','rb')\n",
        "move1_data = open(DATA_PATH+'/MOVE Index 16 18.xlsx','rb')\n",
        "move2_data = open(DATA_PATH+'/MOVE Index Data.xlsx','rb')\n",
        "pd_data = open(DATA_PATH+'/NY Fed Primary Dealer Trade Volumes.xlsx','rb')\n",
        "# df = pd.read_csv(url1,index_col='Date',parse_dates=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpMhtIzV1FuN"
      },
      "source": [
        "#Load our datasets\n",
        "\n",
        "FT_pg1 = pd.read_excel(fi_data, sheet_name=\"20160101_20181130\")\n",
        "FT_pg2 = pd.read_excel(fi_data, sheet_name=\"20181201_20200730\")\n",
        "FT_volumes = pd.concat([FT_pg1,FT_pg2])  #combine the data on top,not a new column\n",
        "\n",
        "move_daily1 = pd.read_excel(move1_data, sheet_name=\"Sheet1\", \n",
        "                           header=1,skiprows=5)\n",
        "\n",
        "move_daily2 = pd.read_excel(move2_data, sheet_name=\"2yr Daily\", \n",
        "                           header=1,skiprows=4)\n",
        "\n",
        "dealer_volumes_df = pd.read_excel(pd_data, sheet_name=\"Sheet1\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTVsPLky4GbL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJZmJZkQ1FuN"
      },
      "source": [
        "FT_volumes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeGgLJak1FuO"
      },
      "source": [
        "from datetime import datetime\n",
        "FT_volumes['Date'] = pd.to_datetime(FT_volumes['Date'].astype(str), format='%Y-%m-%d')\n",
        "FT_volumes.rename(columns={'Non Premium': 'FI Trades'}, inplace=True)\n",
        "\n",
        "weekly_volumes = FT_volumes.groupby(\"Client\").resample('W-Wed',\n",
        "                                                      label='right', \n",
        "                                                      closed = 'right',\n",
        "                                                      on='Date').sum().reset_index().sort_values(by='Date')\n",
        "\n",
        "weekly_volumes = weekly_volumes.groupby(['Date'])['FI Trades'].agg('sum')\n",
        "weekly_df = pd.DataFrame(weekly_volumes)\n",
        "weekly_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ_-lQFP1FuP"
      },
      "source": [
        "weekly_df = weekly_df[:-1]  #remove an august, 2020 print\n",
        "weekly_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Zybg2K1FuS"
      },
      "source": [
        "## Plot out the Trade Volume time series and ETS decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQKGyYuD1FuT"
      },
      "source": [
        "title = 'Weekly Fixed Income Trading Volume'\n",
        "\n",
        "ylabel='Millions of Trades'\n",
        "xlabel='Date'\n",
        "\n",
        "ax = weekly_df.plot(figsize=(12,6), title=title)\n",
        "low = weekly_df.min()\n",
        "high = weekly_df.max()\n",
        "ticks = np.linspace(low,high,15).astype(int)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
        "ax.set_yticks(ticks);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-GmZq01FuT"
      },
      "source": [
        "ets = seasonal_decompose(weekly_df,model='add')\n",
        "ets.plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYh461Dc1FuU"
      },
      "source": [
        "#seems to have a seasonal component\n",
        "#reviewing the first couple seasons\n",
        "weekly_df['FI Trades'][:152].plot();\n",
        "#during end of dec, early jan dropoff, as expected for holiday"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcScBRdi1FuU"
      },
      "source": [
        "## Cleaning up the data from the MOVE Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5j5Ibp1FuU"
      },
      "source": [
        "\n",
        "move_daily1.rename(columns={'Date':'Day','Last Px': 'Date', 'Unnamed: 2':'Last Px'}, inplace=True)\n",
        "\n",
        "#stitch the files together\n",
        "move_daily = pd.concat([move_daily2,move_daily1],ignore_index=True)\n",
        "move_daily.drop(['Day','Unnamed: 3'], axis=1, inplace=True)\n",
        "move_daily.dropna(inplace=True)\n",
        "move_daily.reset_index(drop=True, inplace=True)\n",
        "\n",
        "move_index= move_daily[['Date','Last Px']]\n",
        "move_index.rename(columns={'Last Px': 'MOVE Index'}, inplace=True)\n",
        "move_index['MOVE Index'] = pd.to_numeric(move_index['MOVE Index'], errors='coerce')\n",
        "move_index['Date'] = pd.to_datetime(move_index['Date'], errors='coerce')\n",
        "move_index[\"Date\"] = pd.to_datetime(move_index[\"Date\"], format = '%Y%m').dt.to_period('d')\n",
        "move_index = move_index.dropna()\n",
        "move_index = move_index.reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOaPB3S61FuU"
      },
      "source": [
        "#fix the starting point of the move index to align weekly time series\n",
        "date = '2016-01-04'\n",
        "move_index = move_index[move_index['Date']>(date)]\n",
        "\n",
        "from datetime import datetime\n",
        "move_index['Date'] = pd.to_datetime(move_index['Date'].astype(str), format='%Y-%m-%d')\n",
        "\n",
        "move_index.set_index('Date', inplace=True)\n",
        "\n",
        "#align our dates to fall on same day as others \n",
        "move_weekly = move_index['MOVE Index'].resample('W-WED', origin='start').mean()\n",
        "\n",
        "move_weekly.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2l7b6LL1FuV"
      },
      "source": [
        "move_df = pd.DataFrame(move_weekly)\n",
        "move_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTYOvWo3cjn4"
      },
      "source": [
        "move_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAWdV7Uf1FuV"
      },
      "source": [
        "## Building the Dealer dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jl-h9Tg1FuV"
      },
      "source": [
        "dealer_volumes_df.dropna(axis=1, inplace=True)\n",
        "# dealer_volumes_df.head()\n",
        "dealer_volumes_df = dealer_volumes_df.pivot(index=\"As Of Date\",columns=\"Timeseries\", values='Value (millions)') \\\n",
        "       .reset_index().rename_axis(None, axis=1)\n",
        "dealer_volumes_df.rename(columns={'As Of Date': 'Date',\n",
        "                                  'PDTRGSC-L2':'< 2yr duration',\n",
        "                                  'PDTRGSC-G2L3':'2-3yr duration',\n",
        "                                  'PDTRGSC-G3L6':'3-6yr duration',\n",
        "                                  'PDTRGSC-G6L7':'6-7yr duration',\n",
        "                                  'PDTRGSC-G7L11':'7-11yr duration',\n",
        "                                  'PDTRGSC-G11':'> 11yr duration',\n",
        "                                  }, \n",
        "                         inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mht9dNG91FuW"
      },
      "source": [
        "dealer_volumes_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_ref691FuW"
      },
      "source": [
        "\n",
        "columnsTitles = ['Date','< 2yr duration','2-3yr duration',\n",
        "                 '3-6yr duration','6-7yr duration',\n",
        "                 '7-11yr duration','> 11yr duration']\n",
        "cols = ['< 2yr duration','2-3yr duration',\n",
        "                 '3-6yr duration','6-7yr duration',\n",
        "                 '7-11yr duration','> 11yr duration']\n",
        "dealer_volumes_df = dealer_volumes_df.reindex(columns=columnsTitles)\n",
        "dealer_volumes_df[cols] = dealer_volumes_df[cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "dealer_volumes_df['Date']= pd.to_datetime(dealer_volumes_df['Date'])\n",
        "dealer_volumes_df[['< 2yr duration','2-3yr duration',\n",
        "                 '3-6yr duration','6-7yr duration',\n",
        "                 '7-11yr duration','> 11yr duration']].astype(np.float64)\n",
        "\n",
        "dealer_volumes_df[\"All Treasury Volume\"] = dealer_volumes_df[cols].sum(axis=1) \n",
        "# dealer_volumes_df['> 11yr series'] = pd.to_numeric(dealer_volumes_df['> 11yr series'])\n",
        "print(dealer_volumes_df.dtypes)\n",
        "print(dealer_volumes_df[dealer_volumes_df['All Treasury Volume'].isnull()].shape)\n",
        "dealer_volumes_df.set_index('Date')\n",
        "dealer_volumes_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FFaufyu1FuW"
      },
      "source": [
        "dealer_volumes_df.set_index('Date', inplace=True)\n",
        "\n",
        "print(dealer_volumes_df.dtypes)\n",
        "print(dealer_volumes_df[dealer_volumes_df['All Treasury Volume'].isnull()].shape)\n",
        "dealer_volumes_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh7f8I2c1FuX"
      },
      "source": [
        "weekly_df = weekly_df.join(dealer_volumes_df)\n",
        "\n",
        "weekly_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0zylfIH1FuX"
      },
      "source": [
        "#Bring all dataframes together\n",
        "\n",
        "weekly_df = weekly_df.join(move_df)\n",
        "weekly_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RObRdaDXb5tN"
      },
      "source": [
        "weekly_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrW3ZutDc-lt"
      },
      "source": [
        "weekly_df['MOVE Index'].ffill(axis=0, inplace=True)\n",
        "weekly_df['MOVE Index'].tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuqwgGnBdFli"
      },
      "source": [
        "The MOVE Index is missing data from July.  For now, we're fix that so we can run a balanced analysis but will look to complete that data going forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoN6ZjAq1FuY"
      },
      "source": [
        "# Plot two lines with different scales on the same plot\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "formatter = ticker.StrMethodFormatter('{x:,.0f}')\n",
        "\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "line_weight = 3\n",
        "alpha = .5\n",
        "ax1 = fig.add_axes([0, 0, 1, 1])\n",
        "ax2 = fig.add_axes()\n",
        "# This is the magic that joins the x-axis\n",
        "ax2 = ax1.twinx()\n",
        "lns1 = ax1.plot(weekly_df['FI Trades'], color='blue', lw=line_weight, alpha=alpha, label='FI Trades Volume')\n",
        "lns2 = ax2.plot(weekly_df['All Treasury Volume'], color='green', lw=line_weight, alpha=alpha, label='All Dealer Activity')\n",
        "# Solution for having two legends\n",
        "leg = lns1 + lns2\n",
        "labs = [l.get_label() for l in leg]\n",
        "ax1.legend(leg, labs, loc='best')\n",
        "plt.title('Weekly Fixed Income Volume & Total Primary Dealer Activity in Notional Value', fontsize=20)\n",
        "ax1.set(ylabel=\"FI Volume (mlns)\")  \n",
        "ax2.set(ylabel=\"Dealer Notional Value (mlns)\")\n",
        "\n",
        "ax2.yaxis.set_major_formatter(formatter);\n",
        "plt.savefig('fivol_dealer.png',dpi=60, bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSF5xCD91FuY"
      },
      "source": [
        "# Plot two lines with different scales on the same plot\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "line_weight = 3\n",
        "alpha = .5\n",
        "ax1 = fig.add_axes([0, 0, 1, 1])\n",
        "ax2 = fig.add_axes()\n",
        "# This is the magic that joins the x-axis\n",
        "ax2 = ax1.twinx()\n",
        "lns1 = ax1.plot(weekly_df['FI Trades'], color='blue', lw=line_weight, alpha=alpha, label='FI Trades')\n",
        "lns2 = ax2.plot(weekly_df['MOVE Index'], color='orange', lw=line_weight, alpha=alpha, label='MOVE Index')\n",
        "# Solution for having two legends\n",
        "leg = lns1 + lns2\n",
        "labs = [l.get_label() for l in leg]\n",
        "ax1.legend(leg, labs, loc='best')\n",
        "plt.title('Weekly Fixed Income Trading Activity and MOVE Index', fontsize=20)\n",
        "ax1.set(ylabel=\"FI Volume (mlns)\")  \n",
        "ax2.set(ylabel=\"MOVE Index Level\")\n",
        "\n",
        "plt.savefig('fivol_move.png',dpi=60, bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbZkittP1FuZ"
      },
      "source": [
        "Checking data for stationarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rgkKcON1FuZ"
      },
      "source": [
        "# INCLUDED HERE IF YOU CHOOSE TO USE IT\n",
        "def adf_test(series,title=''):\n",
        "    \"\"\"\n",
        "    Pass in a time series and an optional title, returns an ADF report\n",
        "    \"\"\"\n",
        "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
        "    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n",
        "    \n",
        "    labels = ['ADF test statistic','p-value','# lags used','# observations']\n",
        "    out = pd.Series(result[0:4],index=labels)\n",
        "\n",
        "    for key,val in result[4].items():\n",
        "        out[f'critical value ({key})']=val\n",
        "        \n",
        "    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n",
        "    \n",
        "    if result[1] <= 0.05:\n",
        "        print(\"Strong evidence against the null hypothesis\")\n",
        "        print(\"Reject the null hypothesis\")\n",
        "        print(\"Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print(\"Weak evidence against the null hypothesis\")\n",
        "        print(\"Fail to reject the null hypothesis\")\n",
        "        print(\"Data has a unit root and is non-stationary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQx_QhsL1FuZ"
      },
      "source": [
        "adf_test(weekly_df['FI Trades'], title='Weekly Fixed Income Volumes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaEYMOfw1FuZ"
      },
      "source": [
        "adf_test(weekly_df['MOVE Index'], title='Weekly Fixed Income Volumes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU244Wse1Fua"
      },
      "source": [
        "adf_test(weekly_df['All Treasury Volume'], title='Weekly Fixed Income Volumes')\n",
        "# weekly_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHKwIfM01Fua"
      },
      "source": [
        "weekly_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTMRG9Z0AtWR"
      },
      "source": [
        "#Looking at the ACF and PCF graphs to determine where the FI Trades series could become stationary.\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "print('This plot indicates non-stationary data, as there are a large number of lags before ACF values drop off.')\n",
        "title = 'Autocorrelation: FI Trades'\n",
        "lags = 40\n",
        "plot_acf(weekly_df['FI Trades'],title=title,lags=lags, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrbfsprCDhbE"
      },
      "source": [
        "from statsmodels.tsa.statespace.tools import diff\n",
        "\n",
        "weekly_df['d1'] = diff(weekly_df['FI Trades'],k_diff=1)\n",
        "weekly_df['d1'].plot(figsize=(12,5));\n",
        "\n",
        "title='Autocorrelation: FI Trades First Differencing'\n",
        "lags=40\n",
        "plot_pacf(weekly_df['d1'].dropna(),title=title,lags=np.arange(lags));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dU04bFBFYBa"
      },
      "source": [
        "We can visually see from the plot above that a First Difference lag can transform the Trading series in a stationary one for analyzing.  Another way to understand our dataset and more efficient is to run the auto_arima function.  This provides more concrete detail on how we should model this series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uibxtRJsqvf"
      },
      "source": [
        "#Run ARIMA model to compare AIC score to SARIMA\n",
        "auto_arima(weekly_df['FI Trades'],seasonal=False).summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StDzk0enONy-"
      },
      "source": [
        "auto_arima(weekly_df['FI Trades'],seasonal=True,m=52).summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZHl7w7Ht_Ra"
      },
      "source": [
        "We can see a slight improvement to the AIC score when incorporating seasonality.  The AIC is meant to penalize a model given the added complexity and despite that, our SARIMA model still showed some improvement.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai8zHaXbespT"
      },
      "source": [
        "#Create a variable to analyze our observations for testing and prediction.  Let's forecast for 6mos.\n",
        "nobs = 4 * 6 # weeks * mos\n",
        "# Set four weeks for testing\n",
        "train, test = weekly_df[0:-nobs], weekly_df[-nobs:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4rGrIn2f39s"
      },
      "source": [
        "train.shape\n",
        "test.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DqXGM6Oh7Ax"
      },
      "source": [
        "\t# SARIMAX(0, 1, 2)x(1, 0, [], 52)\n",
        "model = SARIMAX(train['FI Trades'],order=(0,1,2),enforce_invertibility=False,seasonal_order=(1,0,0,52))\n",
        "results = model.fit()\n",
        "results.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwfHDhQahLjf"
      },
      "source": [
        "start=len(train)\n",
        "end=len(train)+len(test)-1\n",
        "predictions = results.predict(start=start, end=end, dynamic=False, typ='levels').rename('SARIMAX(0, 1, 2)x(1, 0, [], 52) Predictions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VEbJO1ZwZ2_"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = test['FI Trades'].plot(legend=True,figsize=(12,6),title=title)\n",
        "predictions.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GP9Y43lTYRb"
      },
      "source": [
        "As we can see above, the first couple months the model didn't track very well.  We failed to capture the spike in activity potentially indicating an exogenous feature contributing to the original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be9T3E2yfHWe"
      },
      "source": [
        "from statsmodels.tools.eval_measures import rmse\n",
        "\n",
        "error = rmse(test['FI Trades'], predictions)\n",
        "print(f'SARIMAX(0, 1, 2)x(1, 0, [], 52)  RMSE Error: {error:11.10}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJYOqCIf2tx0"
      },
      "source": [
        "test_mean = test['FI Trades'].mean()\n",
        "err_val = error/test_mean\n",
        "print(f'Mean of the test set: {test_mean:11.8}')\n",
        "print(f'Our relative error: {err_val:11.5}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeqMLNa59wm2"
      },
      "source": [
        "Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors\n",
        "\n",
        "Let's try including MOVE Index and then the Primary Dealer data\n",
        "\n",
        "In both cases,the Granger Causality Test indicates that when applying as few as 1 weekly lag and at most 2 weekly lags both the MOVE Index and the All Primary Dealer Treasury Volume datasets are useful in forecasting the FI Trading volume data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcPYPffy1OCu"
      },
      "source": [
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "data = weekly_df[['FI Trades','MOVE Index']]\n",
        "data1 = weekly_df[['MOVE Index','FI Trades']]\n",
        "data2 =weekly_df[['FI Trades','All Treasury Volume']]\n",
        "data3 =weekly_df[['All Treasury Volume','FI Trades']]\n",
        "\n",
        "print(\"*MOVE Index comparison*\")\n",
        "grangercausalitytests(data,maxlag=3);\n",
        "print('_______________________________________')\n",
        "print(\"*Primary Dealer comparison*\")\n",
        "grangercausalitytests(data2,maxlag=3);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lsAiBnE9-fa"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = test['FI Trades'].plot(legend=True,figsize=(12,6),title=title)\n",
        "predictions.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
        "\n",
        "# df1[df1['holiday']==1].index\n",
        "for x in test[test['MOVE Index']>80].index: \n",
        "    ax.axvline(x=x, color='k', alpha = 0.3);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRdkVAeS_Z-u"
      },
      "source": [
        "model = SARIMAX(train['FI Trades'],exog=train['MOVE Index'],order=(0,1,2),seasonal_order=(1,0,0,52),enforce_invertibility=True)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThFyxjzzW-O1"
      },
      "source": [
        "Modest improvement in the AIC.  Let's model that result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaqNaaPGXE7p"
      },
      "source": [
        "# Obtain predicted values\n",
        "start=len(train)\n",
        "end=len(train)+len(test)-1\n",
        "exog_forecast = test[['MOVE Index']]  # requires two brackets to yield a shape of (35,1)\n",
        "predictions = results.predict(start=start, end=end, exog=exog_forecast).rename('SARIMAX(0, 1, 2)x(1, 0, [], 52)\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQuwG545XZET"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = test['FI Trades'].plot(legend=True,figsize=(12,6),title=title)\n",
        "predictions.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
        "\n",
        "# df1[df1['holiday']==1].index\n",
        "for x in test[test['MOVE Index']>80].index: \n",
        "    ax.axvline(x=x, color='k', alpha = 0.3);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQDg3pReZ8U5"
      },
      "source": [
        "We can see some improvement in the early months.  Let's review the error again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i54RlP8tamBN"
      },
      "source": [
        "from statsmodels.tools.eval_measures import rmse\n",
        "\n",
        "error = rmse(test['FI Trades'], predictions)\n",
        "print(f'SARIMAX(0, 1, 2)x(1, 0, [], 52)  RMSE Error: {error:11.10}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ2IInLyayOw"
      },
      "source": [
        "test_mean = test['FI Trades'].mean()\n",
        "err_val = error/test_mean\n",
        "print(f'Mean of the test set: {test_mean:11.8}')\n",
        "print(f'Our relative error: {err_val:11.5}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chNGOarQa7Wv"
      },
      "source": [
        "A significant improvement in the relative error from 23% to 16% yet still a big enough error to keep testing on another series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IUDsTGNXZsp"
      },
      "source": [
        "What about the All Treasury data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po0SNdqbfImf"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = test['FI Trades'].plot(legend=True,figsize=(12,6),title=title)\n",
        "predictions.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
        "\n",
        "# df1[df1['holiday']==1].index\n",
        "for x in test[test['All Treasury Volume']>500000].index: \n",
        "    ax.axvline(x=x, color='k', alpha = 0.3);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQEuXTUbXdXy"
      },
      "source": [
        "model = SARIMAX(train['FI Trades'],exog=train['All Treasury Volume'],order=(0,1,2),seasonal_order=(1,0,0,52),enforce_invertibility=True)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbkHGvcLXgqe"
      },
      "source": [
        "# Obtain predicted values\n",
        "start=len(train)\n",
        "end=len(train)+len(test)-1\n",
        "exog_forecast = test[['All Treasury Volume']]  # requires two brackets to yield a shape of (35,1)\n",
        "predictions = results.predict(start=start, end=end, exog=exog_forecast).rename('SARIMAX(0, 1, 2)x(1, 0, [], 52)\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7kKZFjVXjvr"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = test['FI Trades'].plot(legend=True,figsize=(12,6),title=title)\n",
        "predictions.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
        "\n",
        "# df1[df1['holiday']==1].index\n",
        "for x in test[test['All Treasury Volume']>500000].index: \n",
        "    ax.axvline(x=x, color='k', alpha = 0.3);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE5TRLq7gSEZ"
      },
      "source": [
        "This appears to be a significant improvement.  Let's review the errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX9yFbm-gXcK"
      },
      "source": [
        "from statsmodels.tools.eval_measures import rmse\n",
        "\n",
        "error = rmse(test['FI Trades'], predictions)\n",
        "print(f'SARIMAX(0, 1, 2)x(1, 0, [], 52)  RMSE Error: {error:11.10}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb5OF13gp9_"
      },
      "source": [
        "test_mean = test['FI Trades'].mean()\n",
        "err_val = error/test_mean\n",
        "print(f'Mean of the test set: {test_mean:11.8}')\n",
        "print(f'Our relative error: {err_val:11.5}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPaxk5yBg2ia"
      },
      "source": [
        "That's a solid improvement over the MOVE Index.  Now our tracking error is reflects an 11% margin.  Let's retrain the model and forecast the next 6 months, or 24 weeks from July of 2020.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G4qRBWRgxvU"
      },
      "source": [
        "model = SARIMAX(weekly_df['FI Trades'],exog=weekly_df['All Treasury Volume'],order=(0,1,2),seasonal_order=(1,0,0,52),enforce_invertibility=False)\n",
        "results = model.fit()\n",
        "exog_forecast = weekly_df[-nobs:][['All Treasury Volume']]\n",
        "fcast = results.predict(len(weekly_df),len(weekly_df)+23,exog=exog_forecast).rename('SARIMAX(0,1,2)(1,0,0,52) Forecast')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4fEucsUiPN0"
      },
      "source": [
        "# Plot predictions against known values\n",
        "title = 'Weekly Fixed Income Trading Volumes'\n",
        "ylabel='Volume in mlns'\n",
        "xlabel=''\n",
        "\n",
        "ax = weekly_df['FI Trades'][-nobs:].plot(legend=True,figsize=(12,8),title=title)\n",
        "fcast.plot(legend=True)\n",
        "ax.autoscale(axis='x',tight=True)\n",
        "ax.set(xlabel=xlabel, ylabel=ylabel);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzUBqsjkiQT5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lALOlLNplgCP"
      },
      "source": [
        "By adding in the exogenous data of the Primary Dealer activity, we improved our tracking by over 10 points and used that model to predict future trading activity through the remainder of the year and through the uncertain election period and turmoil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptx9fbWjmKmZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}